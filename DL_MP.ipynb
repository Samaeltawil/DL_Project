{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LGKTsh9CPERX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, accuracy_score \n",
        "\n",
        "from preprocessing import create_csv_labels\n",
        "from custom_dataset import CustomDataset\n",
        "from vilbert_adapt import CustomBert\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "on_colab = False\n",
        "create_csv = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au9o9WX5PERZ"
      },
      "source": [
        "# step 1: preprocessing and data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LOznnQ8PERa",
        "outputId": "57b351c4-4a43-4ade-f7c8-cbec34709efb"
      },
      "outputs": [],
      "source": [
        "if on_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    dataset_path = 'drive/MyDrive/DL_project'\n",
        "else:\n",
        "    dataset_path = ''\n",
        "\n",
        "# Load dataset\n",
        "image_path = os.path.join(dataset_path, 'dataset/img_resized')\n",
        "img_text_path = os.path.join(dataset_path, 'dataset/img_txt')\n",
        "json_path = os.path.join(dataset_path, 'dataset/MMHS150K_GT.json')\n",
        "GT_path = os.path.join(dataset_path, 'dataset/MMHS150K_Custom.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create cleaned csv file\n",
        "if create_csv:\n",
        "    filename = os.path.join(dataset_path, \"dataset/MMHS1150K_Custom.csv\")\n",
        "    create_csv_labels(json_path, filename, img_text_path)\n",
        "    GT_path = filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Define transformations for image preprocessing\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizing using ImageNet statistics\n",
        "])\n",
        "\n",
        "dataset = CustomDataset(GT_path, image_path, img_text_path, transform=data_transforms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qMI92anPERa",
        "outputId": "09b5d625-fd75-41fe-d7c6-c5738bd834bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([  101,  1026, 23325, 15900,  1028, 24761,  6508,  6904, 13871,  4140,\n",
              "          1026, 24471,  2140,  1028,   102,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " tensor([-1.6896e+00, -8.1266e-01, -1.9625e-01, -1.7209e+00, -1.9277e-01,\n",
              "          2.1986e+00,  2.2353e+00,  7.5972e-01, -2.5000e+00, -3.5750e+00,\n",
              "         -3.4836e+00, -4.5857e+00, -4.5425e+00, -4.7120e+00, -2.6898e+00,\n",
              "         -4.5091e+00, -2.5502e+00, -2.4132e+00, -4.1988e+00, -3.0051e+00,\n",
              "         -4.8098e+00, -4.2637e+00, -5.2961e+00, -3.0688e+00, -3.2029e+00,\n",
              "         -3.2527e+00, -9.3142e-01, -1.8053e-01, -1.7342e+00, -2.0454e+00,\n",
              "         -1.9398e+00, -3.3382e+00, -1.3806e-02, -7.8990e-02,  1.2438e+00,\n",
              "         -2.2888e+00,  2.5455e-01, -2.1957e+00,  4.7477e-01, -1.7839e+00,\n",
              "         -2.8645e+00, -5.8740e-01, -9.0156e-01,  1.2645e+00, -1.7360e-01,\n",
              "         -5.9924e-01, -2.3206e+00, -3.0483e-01, -4.1989e+00, -1.1249e+00,\n",
              "         -2.0999e+00,  1.0834e+00, -1.2980e+00, -1.8980e+00, -6.0719e-01,\n",
              "         -1.9370e+00, -4.0523e+00, -2.5151e+00, -2.1976e+00, -4.5014e-01,\n",
              "         -9.1836e-01, -1.6969e+00, -4.5619e-01,  1.6949e+00,  1.1205e-01,\n",
              "          3.2031e-01, -1.4273e+00, -7.7134e-01, -1.4157e+00,  1.7768e+00,\n",
              "         -2.9399e+00,  3.8537e+00, -4.3009e+00, -3.1962e+00, -4.5296e+00,\n",
              "         -2.2963e+00,  9.1206e-03, -2.7134e+00,  3.2650e-01,  2.9009e+00,\n",
              "         -5.2515e+00, -6.2570e+00, -2.2477e+00, -2.7621e+00, -4.4702e+00,\n",
              "         -3.7954e+00, -1.8877e+00, -2.4954e+00, -1.7399e-01, -5.1459e+00,\n",
              "         -8.5638e-01, -2.9153e+00, -9.5403e-01, -5.5996e+00, -1.5712e+00,\n",
              "         -3.6643e+00, -4.3775e+00, -5.1769e+00, -2.9253e+00, -5.0362e+00,\n",
              "         -4.1157e+00, -1.1701e+00, -4.6868e-01,  2.6314e-02, -2.5374e+00,\n",
              "         -2.1596e+00, -1.3268e+00,  2.9566e+00,  2.9706e+00,  8.5719e-01,\n",
              "          1.2720e+00,  1.9360e+00,  4.6553e+00,  1.4076e+00,  1.4894e-01,\n",
              "          3.9152e-01,  2.2839e-01, -2.3270e-01,  2.0830e-01, -3.3228e-01,\n",
              "          1.1494e+00, -1.5365e+00,  8.1098e-01,  1.0763e+00,  3.5813e+00,\n",
              "          4.1329e-01,  2.0669e+00, -5.4228e+00, -3.7158e+00, -2.6909e+00,\n",
              "         -2.3810e+00, -4.3651e+00, -5.8423e+00, -5.1309e+00, -5.8358e+00,\n",
              "         -4.4056e+00, -2.8411e+00, -5.1962e+00, -4.5448e+00, -3.3915e+00,\n",
              "         -2.8549e+00, -3.7291e+00, -3.8251e+00, -4.3557e+00, -5.2012e+00,\n",
              "         -3.3433e+00, -4.5535e+00, -3.5947e+00, -1.3863e+00, -1.2579e+00,\n",
              "         -2.2975e-01,  3.2936e+00,  1.9014e+00,  6.2586e-01,  2.3503e+00,\n",
              "          1.2146e+00,  4.3378e-01,  1.4621e+00, -4.3661e-01,  1.6983e+00,\n",
              "         -1.8166e-01, -3.9785e-01, -1.2041e+00,  1.1014e+00, -6.4708e-01,\n",
              "         -7.1890e-01, -2.3850e+00, -1.6089e+00,  1.9697e+00, -9.4378e-01,\n",
              "         -2.1041e+00,  1.7135e+00, -6.6496e-01, -1.1858e+00, -6.9550e-01,\n",
              "         -1.8776e+00, -1.6238e+00, -2.9248e+00,  1.3992e+00,  1.3901e+00,\n",
              "          2.8731e-01, -1.5561e+00, -1.0774e+00, -9.9386e-01, -1.6119e+00,\n",
              "         -2.5200e-01,  6.1084e-01,  1.9455e+00, -7.7131e-01, -6.0884e-01,\n",
              "         -1.3666e+00, -2.4690e+00, -1.6334e+00,  9.8529e-01, -1.0624e+00,\n",
              "          1.7000e+00, -8.7669e-01, -3.5386e-01,  2.7086e-01, -1.4166e+00,\n",
              "          3.2571e-01, -9.3452e-01,  7.9514e-01, -8.5557e-02,  9.1904e-01,\n",
              "         -3.7061e+00, -1.3179e+00,  1.5924e+00,  1.6365e-01, -1.0996e+00,\n",
              "         -4.8348e-01,  3.2915e+00, -2.7799e+00,  3.9335e-01, -6.8880e-01,\n",
              "         -1.5987e+00, -1.5831e+00, -2.1953e+00, -2.4253e+00,  7.5283e-01,\n",
              "          9.7543e-01, -7.9852e-01,  4.3685e-01, -8.5901e-01, -5.1046e-01,\n",
              "          7.2996e-01, -2.0241e+00,  5.8021e-01, -5.3487e-01, -1.2868e+00,\n",
              "          7.0456e-01,  1.1297e-01, -8.5280e-01,  4.6799e-01,  7.4052e-01,\n",
              "          4.4662e-01,  2.3298e-01,  6.4835e-01, -4.8344e-01, -3.9982e-01,\n",
              "          2.1165e-01, -2.0966e+00,  2.7897e+00,  3.0267e+00,  1.7737e+00,\n",
              "          1.6901e+00,  2.3142e+00, -1.7969e-01, -3.0704e-01, -8.4977e-01,\n",
              "         -1.4660e-01, -2.0308e+00,  4.6914e-01, -2.6444e-01,  2.8144e+00,\n",
              "         -1.7966e+00,  7.5542e-01,  4.7674e-01, -1.0094e+00,  1.0648e+00,\n",
              "          1.2302e+00,  2.3750e-01,  1.2600e+00, -1.2902e+00, -1.9114e+00,\n",
              "          5.4105e-01, -1.2992e+00, -1.3978e+00,  1.6844e+00, -7.2803e-01,\n",
              "         -1.4175e+00, -1.1890e+00, -1.1061e+00,  1.6808e+00, -2.4844e+00,\n",
              "         -4.4327e+00, -3.6383e+00, -5.5464e-01, -1.2905e+00, -2.7065e-01,\n",
              "         -2.6696e-01,  4.4198e-01, -1.2786e+00, -5.4430e-01, -4.1906e-01,\n",
              "          6.7414e-01,  2.0357e+00, -1.2840e+00, -1.1159e+00, -1.9375e+00,\n",
              "         -1.1039e+00,  3.1680e-01, -9.7520e-01, -6.6047e-01, -4.2147e+00,\n",
              "         -3.7174e+00, -3.0206e+00, -3.0025e+00, -1.1362e+00,  1.9606e+00,\n",
              "         -2.7714e+00, -3.1749e+00, -6.0449e-01, -1.6558e+00, -3.3146e+00,\n",
              "         -2.2535e+00,  3.1293e-01, -2.5048e+00, -2.9864e+00, -1.0181e+00,\n",
              "          5.1594e-02, -1.8268e+00, -2.4330e-01, -1.5766e-01,  1.7398e+00,\n",
              "         -1.9745e+00, -3.0382e+00, -3.8050e+00, -1.4044e+00, -2.7281e+00,\n",
              "         -2.7041e+00, -1.4992e+00, -4.6319e-01, -4.6841e-01, -1.3898e+00,\n",
              "         -2.3791e-02, -2.9360e+00,  3.9531e+00,  1.5071e+00,  1.8092e+00,\n",
              "         -1.2201e+00, -1.5489e+00, -1.4967e+00, -1.5202e-01, -1.0257e+00,\n",
              "         -1.9103e+00, -4.0492e+00, -3.1880e+00, -2.9251e-01,  1.5376e+00,\n",
              "         -1.1356e+00, -1.7552e-01, -2.5395e+00, -5.4694e+00, -2.0054e+00,\n",
              "          8.9378e-01, -1.7216e+00, -2.3616e+00, -1.8071e+00, -1.4911e+00,\n",
              "         -1.7232e+00, -3.1387e+00, -1.2645e+00, -1.9974e+00,  2.1539e-01,\n",
              "         -5.7090e-01, -1.9787e-01, -1.1517e+00,  1.8993e-01,  4.4844e-01,\n",
              "         -2.2477e+00, -4.5262e-01, -1.3961e-01, -1.4430e+00, -2.1321e+00,\n",
              "          2.2429e+00, -7.4146e-01, -8.5580e-01, -6.3649e-01, -1.2528e+00,\n",
              "         -1.0020e+00, -7.2329e-01, -5.9313e-01,  2.4070e+00, -2.5884e+00,\n",
              "         -3.2767e+00,  6.4544e-01, -3.8934e-01, -3.2990e-01, -1.8272e+00,\n",
              "          1.3783e+00, -1.7874e+00, -7.5613e-01, -2.9942e+00, -2.4035e+00,\n",
              "          4.7888e-01, -2.7206e+00, -4.2577e+00, -4.1599e+00, -2.4890e-01,\n",
              "         -1.6322e+00, -6.5033e-01, -1.1353e-01, -2.8404e-01, -2.0290e+00,\n",
              "         -6.2814e-01, -8.8249e-01,  1.0042e-01,  2.0397e+00,  2.5239e+00,\n",
              "          2.8304e+00,  2.0167e+00, -1.3277e-01, -3.1725e+00, -4.7970e+00,\n",
              "         -1.5518e+00, -1.2448e+00, -2.3764e+00, -5.8080e-01,  8.3019e-01,\n",
              "         -5.3454e+00,  6.3335e-01,  2.7600e-01, -8.0376e-01,  2.3118e-01,\n",
              "          2.4770e-01,  3.2733e+00,  2.1617e+00,  2.3626e-02,  7.3204e+00,\n",
              "         -2.6627e-01, -2.7393e+00,  5.2535e+00,  2.0136e-01,  1.7460e+00,\n",
              "         -2.4712e+00, -2.1096e-01,  5.9498e-01, -1.9061e+00,  6.3612e-02,\n",
              "          2.6203e+00, -2.5517e+00,  8.2889e-01,  9.7256e+00,  6.1693e+00,\n",
              "          6.1427e+00, -3.5190e-01, -9.4663e-01,  1.9423e+00,  1.7422e+00,\n",
              "          7.5576e-01,  8.7220e-01, -6.4707e-01,  1.2110e-01, -3.5622e-01,\n",
              "          1.1091e+01, -1.5709e-01,  1.9496e+00, -3.3776e+00, -2.6567e+00,\n",
              "         -2.1085e+00, -8.9435e-02,  3.6684e+00,  6.4562e-01,  2.9721e+00,\n",
              "          2.6475e+00,  1.6540e+00,  5.5686e+00,  2.5585e+00,  9.7906e+00,\n",
              "         -1.6225e+00,  4.4803e-01,  1.2496e+00,  3.5205e+00,  1.8462e+00,\n",
              "         -1.4155e-01, -3.8436e+00,  2.4645e+00, -1.4793e+00,  5.5864e-01,\n",
              "          3.2509e+00, -3.3013e+00, -1.7752e+00,  1.0579e+00,  1.6777e+00,\n",
              "          3.1127e-01,  1.7828e-01,  6.3067e-01,  3.6639e+00, -1.3125e+00,\n",
              "          3.1277e+00,  2.5836e+00,  5.1965e-02, -2.6536e-02,  5.7832e-01,\n",
              "         -8.7486e-01, -1.5164e+00,  6.7373e+00,  4.6570e+00,  2.0953e+00,\n",
              "          3.0246e+00, -1.0311e-01, -9.8463e-01, -3.0946e+00, -2.5214e+00,\n",
              "         -3.8535e+00, -6.9578e-01, -3.1978e+00,  2.4483e+00,  9.3617e-01,\n",
              "         -1.6347e-01,  2.4711e+00,  1.9449e+00,  1.2243e+00,  2.9418e+00,\n",
              "         -1.8473e+00, -7.6759e-01,  4.7070e+00,  3.6508e+00,  1.8023e+00,\n",
              "         -6.0136e-01,  6.1714e-02, -2.1306e+00,  2.0319e+00,  2.0919e+00,\n",
              "          4.1054e+00, -2.0915e+00, -2.7137e-01, -1.0050e+00,  2.3843e+00,\n",
              "         -1.6577e+00, -1.1968e+00, -3.6682e-01,  2.7527e+00,  6.1173e-01,\n",
              "         -2.1499e+00, -9.6918e-02,  2.1691e-02,  2.0729e+00,  5.8840e+00,\n",
              "          1.7169e+00,  3.8059e+00, -1.5674e+00,  2.3865e+00,  8.9416e-01,\n",
              "         -2.0624e+00, -2.8799e+00, -3.2461e+00, -5.3993e+00,  2.6476e+00,\n",
              "         -9.3075e-01,  1.7035e-01,  2.7646e+00,  6.5222e+00, -4.1686e+00,\n",
              "         -1.0769e+00, -2.8035e-01, -3.2538e+00, -2.7793e+00,  3.0261e+00,\n",
              "         -6.9600e-01,  6.8381e+00,  7.5208e+00, -2.2688e+00, -4.0110e+00,\n",
              "         -1.5618e-02, -3.0182e+00, -1.1049e+00,  1.1808e+00,  1.7362e-01,\n",
              "         -1.3242e+00, -1.0662e+00,  6.6996e-01, -2.3785e+00, -3.1568e+00,\n",
              "         -2.1035e+00,  7.4388e-01, -4.0434e-01,  5.3793e+00, -6.1313e-01,\n",
              "          2.6246e+00, -2.3098e-01,  2.7275e-01, -1.5718e+00, -1.5170e+00,\n",
              "         -3.7790e-01, -3.0309e+00,  1.4677e+00,  6.6987e+00, -3.5346e-01,\n",
              "         -2.0448e+00, -2.8085e+00,  1.5607e+00,  2.6391e+00,  6.0876e+00,\n",
              "          1.1207e+01, -4.3396e-01,  8.4495e-01,  1.0679e+00,  4.9621e+00,\n",
              "          1.8938e+00,  3.5266e+00, -7.8962e-01,  2.5527e+00,  2.1192e+00,\n",
              "         -1.9600e+00, -1.1065e-01, -1.0125e+00, -1.6978e+00,  6.7536e-01,\n",
              "          1.4775e+00,  3.9743e+00,  2.6333e+00, -1.0521e+00,  1.7064e+00,\n",
              "          3.5833e+00,  2.7256e+00, -7.7520e-01,  3.6387e+00, -1.8126e+00,\n",
              "          4.3442e+00,  2.4346e+00,  5.4856e-01,  5.8498e-02, -4.3500e-02,\n",
              "          2.6594e+00,  1.0621e+00,  2.2847e+00, -2.2824e+00, -2.0975e+00,\n",
              "          8.2037e-01, -9.5288e-01,  1.0705e+00, -1.2026e+00,  2.0369e-02,\n",
              "         -2.5974e+00,  4.2873e+00,  3.0128e+00, -1.6281e+00,  8.0211e+00,\n",
              "         -9.0622e-01,  8.6465e+00, -1.3407e+00,  1.9254e+00, -2.5563e+00,\n",
              "          1.7640e+00,  2.6121e+00, -1.7381e-01,  9.6755e+00,  8.3757e+00,\n",
              "         -2.4466e+00,  3.0872e+00,  3.4640e-01,  4.0684e+00,  1.4904e+00,\n",
              "         -4.3767e-02,  3.2791e-01,  1.5092e+00,  1.9908e+00, -7.4344e-01,\n",
              "          4.9169e+00, -1.7563e+00,  1.0341e+00, -8.6212e-01,  1.2291e+00,\n",
              "          6.6630e+00, -3.7309e-01, -3.4821e+00,  9.0804e-01, -1.2708e+00,\n",
              "         -1.9790e+00, -2.1243e+00,  7.5066e-01, -3.0231e+00,  1.7966e+00,\n",
              "         -2.6626e+00, -4.3785e-02,  2.8158e+00, -3.4481e+00,  1.3628e+00,\n",
              "         -1.1280e+00,  6.2624e-01, -2.7332e+00,  1.5659e+00,  1.6856e+00,\n",
              "          1.1687e+00,  3.6652e+00,  1.4594e+00,  5.5416e+00,  2.7348e+00,\n",
              "          3.5308e+00,  2.1802e+00, -5.4054e-02,  1.7784e+00,  7.1773e-01,\n",
              "         -1.3652e+00,  3.0794e+00, -2.5661e+00,  1.5374e-01,  3.4489e+00,\n",
              "          4.6385e-01,  3.0333e+00,  6.5680e+00,  9.7584e-02, -1.3513e+00,\n",
              "          1.0784e+00,  1.7706e+00,  4.8305e+00, -1.2980e+00,  5.4965e+00,\n",
              "          8.8527e-01,  8.2505e-01,  1.3141e+00, -4.4330e-01, -8.0764e-01,\n",
              "         -3.9666e+00, -3.9420e+00,  1.5831e+00, -1.9218e+00,  8.3573e-01,\n",
              "          1.6953e+00,  7.5785e+00,  2.7179e+00,  4.5910e-01,  4.0883e+00,\n",
              "          5.1216e-01,  8.0114e-01, -1.3237e+00,  2.6149e-01,  1.9086e+00,\n",
              "          6.5601e+00, -3.6715e-02,  2.2629e+00, -1.2837e+00, -5.1177e-01,\n",
              "         -1.1065e+00, -1.7431e+00, -1.7018e+00,  3.9442e+00, -2.4933e+00,\n",
              "         -2.9374e+00,  4.7562e+00,  1.3148e+00,  4.2531e+00, -2.8873e+00,\n",
              "          4.3368e+00,  4.1680e-01,  3.1897e+00, -1.8630e+00,  2.4844e+00,\n",
              "          2.5168e+00,  1.4360e+00,  3.8423e-01,  2.4802e+00, -2.6219e+00,\n",
              "         -6.1820e-01, -7.6490e-01,  2.8138e+00,  2.3320e-01,  1.3498e+00,\n",
              "         -8.5003e-01, -1.7787e+00,  2.0054e+00, -1.8516e+00, -1.2354e+00,\n",
              "         -2.4490e+00, -2.6547e+00, -1.1755e+00,  1.0795e+00,  1.4517e+00,\n",
              "          1.3147e+00,  2.8422e+00,  4.8211e-01,  2.0337e+00, -4.6545e-01,\n",
              "         -2.9491e+00, -6.7525e-01,  2.6726e+00, -8.8071e-01,  4.0818e+00,\n",
              "          1.6764e+00,  1.4862e+00,  2.6479e+00,  5.2943e-01,  4.8620e+00,\n",
              "          9.4871e+00,  1.7416e+00, -1.4856e+00,  3.3300e+00, -1.2438e+00,\n",
              "         -2.4579e+00,  4.7854e-01,  2.4008e+00,  1.8197e+00,  1.1307e+00,\n",
              "          2.0322e+00,  1.4009e+00, -1.6677e+00,  3.4854e+00, -4.7422e-01,\n",
              "          1.7596e+00,  1.5827e+00,  7.5470e-02,  8.7958e+00,  4.1585e+00,\n",
              "         -1.0022e+00,  1.3433e+00,  3.6481e+00,  1.0217e-01, -1.8395e+00,\n",
              "          1.3552e+00,  5.7406e+00, -5.0389e+00, -4.1525e+00,  1.6695e+00,\n",
              "          5.0502e-01,  1.9913e+00, -3.5733e+00,  5.3312e+00, -1.3279e+00,\n",
              "          3.2036e+00, -8.4227e-03, -2.3292e+00, -7.6283e-01, -2.8910e-01,\n",
              "         -4.0225e+00, -6.9108e-01, -2.9936e+00,  1.2827e+00,  2.7000e+00,\n",
              "         -2.8058e+00, -1.8291e+00,  9.5773e-01,  4.0790e+00,  5.6467e+00,\n",
              "         -1.9548e+00,  1.7616e+00, -2.4988e+00,  9.9224e-01, -1.2028e+00,\n",
              "         -4.2439e-02,  5.8117e-01, -1.3339e+00, -3.2093e+00,  2.4016e+00,\n",
              "         -2.3240e+00,  5.7370e+00,  6.2941e+00,  1.0278e+01, -1.6058e+00,\n",
              "          5.0366e+00,  3.1913e+00,  9.8923e+00,  2.3373e+00,  1.4092e+00,\n",
              "          5.2990e+00, -1.9812e+00, -2.3732e+00, -7.9599e-01, -1.6670e+00,\n",
              "          6.4760e-01,  1.4039e+00,  2.2412e+00, -6.0958e-02,  3.8361e+00,\n",
              "          1.2034e+00, -3.1707e+00,  4.1419e-01, -1.9801e+00, -1.9294e-01,\n",
              "          1.9383e+00,  1.2596e+00,  3.4174e+00, -2.5706e+00, -2.4030e+00,\n",
              "          1.0291e+00,  7.3377e-01,  3.6400e-01,  2.1486e+00,  1.1949e+00,\n",
              "         -2.3272e-01, -2.2522e+00,  5.3888e-01, -1.8332e+00, -4.0851e+00,\n",
              "          1.9944e+00,  5.4341e+00, -5.6040e-01,  2.6058e+00,  2.5345e+00,\n",
              "         -4.0339e-01, -8.7515e-01,  6.9386e-01, -4.8778e-01, -2.9685e+00,\n",
              "          3.3067e+00,  2.6691e+00, -1.0411e+00, -3.4269e+00,  1.4387e+00,\n",
              "          5.2992e+00, -2.9332e+00,  2.7367e-01,  8.0120e-01,  4.9778e-01,\n",
              "         -3.7971e+00,  9.4241e-01,  2.0847e+00,  4.5851e+00,  4.9847e-01,\n",
              "         -3.2863e+00,  4.3827e-01,  5.1557e+00,  1.1130e+01, -7.1208e-01,\n",
              "         -2.8050e+00,  2.0336e+00,  7.8037e-01, -5.7296e+00, -2.3340e+00,\n",
              "          9.5358e-02,  4.4941e+00, -6.0053e-01, -3.2757e-01, -4.2910e+00,\n",
              "         -2.4873e+00,  7.0979e+00,  7.6282e+00,  3.7720e+00, -5.5326e-01,\n",
              "         -2.2109e+00,  9.7332e+00,  3.2490e+00, -8.8736e-01, -1.1294e+00,\n",
              "         -1.7243e+00, -3.9939e+00, -3.2933e+00, -4.8225e-01,  5.5136e+00,\n",
              "         -2.7078e+00, -2.2477e+00,  2.7523e+00, -1.0600e+00,  4.6087e-01,\n",
              "         -1.1747e+00,  2.1215e+00,  6.8140e-01,  8.9494e-01, -1.2920e+00,\n",
              "         -8.1576e-01, -4.6022e-01,  3.1402e-01,  4.1708e-01, -7.2696e-01,\n",
              "          1.0358e+00, -5.3665e-01, -1.6366e+00,  1.1208e+00,  9.4560e-01,\n",
              "         -1.1509e+00, -1.8747e+00, -1.4250e+00, -1.1997e+00, -7.5597e-01,\n",
              "          6.5747e-01,  9.1903e-01,  1.8364e+00,  4.1377e-01, -2.1419e+00,\n",
              "          5.6578e-02,  3.2559e-01, -1.4802e+00, -2.9746e+00, -2.8234e+00,\n",
              "         -1.3030e-02,  2.5897e+00, -1.0766e+00, -1.2956e-01,  1.2215e+00,\n",
              "          1.6910e-01,  4.1870e+00,  2.5495e+00,  3.1077e+00, -9.9259e-01,\n",
              "          5.0998e-01, -1.1315e-01,  3.7847e+00,  3.4640e+00, -2.0184e+00,\n",
              "          1.7562e+00,  4.8998e-01,  2.9943e+00,  1.0410e+00,  3.4243e+00,\n",
              "         -2.6770e+00, -3.4206e+00,  2.3411e+00, -1.2282e+00, -2.5002e+00,\n",
              "         -2.6910e+00, -3.8156e-01, -3.2367e+00,  2.3252e+00, -1.1715e+00,\n",
              "         -6.6966e-01,  4.0897e-01, -2.6008e+00,  1.3474e+00,  2.5914e+00]),\n",
              " tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
              " tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
              "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
              "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
              "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
              "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
              "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
              "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
              "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
              "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
              "         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
              "         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
              "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
              "         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
              "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
              "         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
              "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
              "         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
              "         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
              "         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
              "         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
              "         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
              "         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
              "         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
              "         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
              "         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
              "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
              "         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
              "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
              "         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
              "         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
              "         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
              "         504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
              "         518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n",
              "         532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
              "         546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n",
              "         560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n",
              "         574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n",
              "         588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
              "         602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n",
              "         616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,\n",
              "         630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n",
              "         644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
              "         658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671,\n",
              "         672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
              "         686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699,\n",
              "         700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713,\n",
              "         714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
              "         728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741,\n",
              "         742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755,\n",
              "         756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769,\n",
              "         770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783,\n",
              "         784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797,\n",
              "         798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811,\n",
              "         812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825,\n",
              "         826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839,\n",
              "         840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853,\n",
              "         854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867,\n",
              "         868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881,\n",
              "         882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895,\n",
              "         896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
              "         910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923,\n",
              "         924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937,\n",
              "         938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951,\n",
              "         952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965,\n",
              "         966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979,\n",
              "         980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993,\n",
              "         994, 995, 996, 997, 998, 999]),\n",
              " tensor([1.]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# visual inspection\n",
        "dataset[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8bjhiu30PERc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n",
            "<torch.utils.data.dataset.Subset object at 0x00000285C7B86110>\n",
            "<torch.utils.data.dataset.Subset object at 0x00000285C7D5FAD0>\n",
            "<torch.utils.data.dataset.Subset object at 0x00000285C7D5C890>\n",
            "now\n",
            "now\n",
            "now\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:472: UserWarning: Length of split at index 2 is 0. This might result in an empty dataset.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now\n",
            "now\n",
            "now\n",
            "now\n",
            "now\n",
            "now\n",
            "now\n",
            "here\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters -------------------------------------------------------\n",
        "import numpy as np\n",
        "batch_size = 5\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Split dataset into training, validation, and test sets\n",
        "dataset_size = len(dataset)\n",
        "print(dataset_size)\n",
        "train_set, test_set, val_set = torch.utils.data.dataset.random_split(dataset, [0.8, 0.1, 0.1])\n",
        "# train_set = np.floor(train_set)\n",
        "# test_set = round(test_set)\n",
        "# val_set = round(val_set)\n",
        "\n",
        "print(train_set) \n",
        "print(test_set) \n",
        "print(val_set)\n",
        "\n",
        "# Create data loader for training set\n",
        "not_hate_indices = []\n",
        "hate_indices = []\n",
        "for idx in range(len(train_set)):\n",
        "    if train_set[idx][5] == 1:\n",
        "        hate_indices.append(idx)\n",
        "    else:\n",
        "        not_hate_indices.append(idx)\n",
        "\n",
        "num_not_hate = len(not_hate_indices)\n",
        "num_hate = len(hate_indices)\n",
        "total_samples = num_not_hate + num_hate\n",
        "\n",
        "# Create a WeightedRandomSampler to balance the training dataset\n",
        "class_weights = [1-num_hate/total_samples, 1-num_not_hate/ total_samples]  # Inverse of number of samples per class\n",
        "\n",
        "weights = []\n",
        "for idx in range(len(train_set)):\n",
        "    try:\n",
        "        label = dataset[idx][5]\n",
        "        according_weights = class_weights[int(label)]\n",
        "        weights.append(according_weights)\n",
        "    except:\n",
        "        print(f\"Error with idx: {idx}\")\n",
        "        print(f\"Label: {dataset[idx][5]}\")\n",
        "\n",
        "# weights = [class_weights[int(dataset[idx]['label'])] for idx in train_indices]\n",
        "sampler = WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "# Create data loader for balanced training set\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=sampler)\n",
        "print(\"here\")\n",
        "\n",
        "# Create data loaders for validation and test sets\n",
        "validation_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Moo9Uy85PERc"
      },
      "source": [
        "# step 2: Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9vwPvJ4qPERd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CustomBert(\n",
            "  (text_bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (visual_bert): VisualBertModel(\n",
            "    (embeddings): VisualBertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (visual_token_type_embeddings): Embedding(2, 768)\n",
            "      (visual_position_embeddings): Embedding(512, 768)\n",
            "      (visual_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "    )\n",
            "    (encoder): VisualBertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x VisualBertLayer(\n",
            "          (attention): VisualBertAttention(\n",
            "            (self): VisualBertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): VisualBertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): VisualBertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): VisualBertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): VisualBertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (classifier): Linear(in_features=1536, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = CustomBert()\n",
        "print(model) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now\n",
            "now\n",
            "now\n",
            "now\n",
            "now\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 94\u001b[0m\n\u001b[0;32m     92\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACC\u001b[39m\u001b[38;5;124m'\u001b[39m: acc}\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[9], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, metrics, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     26\u001b[0m text, mask, images, image_mask, visual_token, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisual_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\OneDrive\\Desktop\\Epfl\\MA2\\Deep Learning\\DL_Project\\vilbert_adapt.py:34\u001b[0m, in \u001b[0;36mCustomBert.forward\u001b[1;34m(self, input_ids, attention_mask, visual_embeddings, image_attention_mask, visual_token)\u001b[0m\n\u001b[0;32m     31\u001b[0m pooled_text_output \u001b[38;5;241m=\u001b[39m text_outputs\u001b[38;5;241m.\u001b[39mpooler_output  \u001b[38;5;66;03m# Use the pooled output from BERT\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Process image inputs using VisualBERT\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m visual_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual_bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisual_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mimage_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvisual_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m pooled_image_output \u001b[38;5;241m=\u001b[39m visual_inputs\u001b[38;5;241m.\u001b[39mpooler_output  \u001b[38;5;66;03m# Use the pooled output from VisualBERT\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Concatenate text and image features\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\visual_bert\\modeling_visual_bert.py:795\u001b[0m, in \u001b[0;36mVisualBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, visual_embeds, visual_attention_mask, visual_token_type_ids, image_text_alignment, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    793\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 795\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisual_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisual_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisual_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisual_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_text_alignment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_text_alignment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbypass_transformer \u001b[38;5;129;01mand\u001b[39;00m visual_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    806\u001b[0m     text_length \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\visual_bert\\modeling_visual_bert.py:111\u001b[0m, in \u001b[0;36mVisualBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, visual_embeds, visual_token_type_ids, image_text_alignment)\u001b[0m\n\u001b[0;32m    108\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids[:, :seq_length]\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sama Wael\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
          ]
        }
      ],
      "source": [
        "\n",
        "def train_model(model, train_loader, val_loader, metrics, num_epochs=1, learning_rate=0.001):\n",
        "    torch.cuda.empty_cache()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    epoch_metrics = dict(zip(metrics.keys(), torch.zeros(len(metrics))))\n",
        "    \n",
        "    train_loss_log,  test_loss_log = [], []\n",
        "    metrics_names = list(metrics.keys())\n",
        "    train_metrics_log = [[] for i in range(len(metrics))]\n",
        "    test_metrics_log = [[] for i in range(len(metrics))]\n",
        "\n",
        "    criterion = nn.BCELoss() # Binary cross-entropy loss\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            # print(f\"Batch {i}\")\n",
        "            batch = [b.to(device) for b in batch]\n",
        "            text, mask, images, image_mask, visual_token, labels = batch\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(text, mask, images, image_mask, visual_token)\n",
        "            loss = criterion(outputs, labels.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            predicted = (outputs.detach() > 0.5)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            # compute metrics\n",
        "            # no gradients should be propagated at this step\n",
        "            with torch.no_grad():\n",
        "                for k in epoch_metrics.keys():\n",
        "                    epoch_metrics[k] += metrics[k](predicted, labels)\n",
        "\n",
        "        for k in epoch_metrics.keys():\n",
        "          epoch_metrics[k] /= len(train_loader)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_accuracy = correct / total\n",
        "\n",
        "        clear_output() #clean the prints from previous epochs\n",
        "        print('train Loss: {:.4f}, '.format(train_loss),\n",
        "            ', '.join(['{}: {:.4f}'.format(k, epoch_metrics[k]) for k in epoch_metrics.keys()]))\n",
        "\n",
        "\n",
        "        train_loss_log.append(train_loss)\n",
        "        train_metrics_log = update_metrics_log(metrics_names, train_metrics_log, epoch_metrics)\n",
        "\n",
        "        plot_training(train_loss_log, metrics_names, train_metrics_log)\n",
        "        \n",
        "        # # Validation phase\n",
        "        # ...\n",
        "\n",
        "        # # Testing phase\n",
        "        # test_loss_log.append(test_loss)\n",
        "        # test_metrics_log = update_metrics_log(metrics_names, test_metrics_log, test_metrics)\n",
        "\n",
        "\n",
        "        # # Validation phase\n",
        "        # model.eval()\n",
        "        # val_loss = 0.0\n",
        "        # correct = 0\n",
        "        # total = 0\n",
        "\n",
        "\n",
        "        # with torch.no_grad():\n",
        "        #     for batch in train_loader:\n",
        "        #         batch = [b.to(device) for b in batch]\n",
        "        #         text, mask, labels = batch\n",
        "        #         outputs = model(text, mask)\n",
        "        #         loss = criterion(outputs, labels.float())\n",
        "        #         val_loss += loss.item() * text.size(0)\n",
        "        #         _, predicted = torch.max(outputs.data, 1)\n",
        "        #         total += labels.size(0)\n",
        "        #         correct += (predicted == labels.sum().item())\n",
        "        # val_loss = val_loss / len(val_loader.dataset)\n",
        "        # val_accuracy = correct / total\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "        # print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "def acc(preds, target):\n",
        "    return accuracy_score(target.detach().cpu(), preds.detach().cpu())\n",
        "\n",
        "metrics = {'ACC': acc}\n",
        "# Example usage\n",
        "train_model(model, train_loader, validation_loader, metrics, num_epochs=5, learning_rate=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iwhxgMDbPERd",
        "outputId": "86fd4f13-f8d5-4a09-a705-d7fbb6a91ac7"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 54\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;66;03m# print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[9], line 27\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     25\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m (outputs\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     26\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     29\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# def train_model(model, train_loader, val_loader, num_epochs=1, learning_rate=0.001):\n",
        "#     torch.cuda.empty_cache()\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     # device = torch.device(\"cpu\")\n",
        "#     model.to(device)\n",
        "\n",
        "#     criterion = nn.BCELoss() # Binary cross-entropy loss\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         # Training phase\n",
        "#         model.train()\n",
        "#         running_loss = 0.0\n",
        "#         correct = 0\n",
        "#         total = 0\n",
        "#         for i,batch in enumerate(train_loader):\n",
        "#             # print(f\"Batch {i}\")\n",
        "#             batch = [b.to(device) for b in batch]\n",
        "#             text, mask, labels = batch\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(text, mask)\n",
        "#             loss = criterion(outputs, labels.float())\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             predicted = (outputs.detach() > 0.5)\n",
        "#             total += labels.size(0)\n",
        "#             correct += (predicted == labels).sum().item()\n",
        "#             running_loss += loss.item() * labels.size(0)\n",
        "#         train_loss = running_loss / len(train_loader.dataset)\n",
        "#         train_accuracy = correct / total\n",
        "\n",
        "#         # # Validation phase\n",
        "#         # model.eval()\n",
        "#         # val_loss = 0.0\n",
        "#         # correct = 0\n",
        "#         # total = 0\n",
        "#         # with torch.no_grad():\n",
        "#         #     for batch in train_loader:\n",
        "#         #         batch = [b.to(device) for b in batch]\n",
        "#         #         text, mask, labels = batch\n",
        "#         #         outputs = model(text, mask)\n",
        "#         #         loss = criterion(outputs, labels.float())\n",
        "#         #         val_loss += loss.item() * text.size(0)\n",
        "#         #         _, predicted = torch.max(outputs.data, 1)\n",
        "#         #         total += labels.size(0)\n",
        "#         #         correct += (predicted == labels.sum().item())\n",
        "#         # val_loss = val_loss / len(val_loader.dataset)\n",
        "#         # val_accuracy = correct / total\n",
        "\n",
        "#         print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "#         # print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "# # Example usage\n",
        "# train_model(model, train_loader, validation_loader, num_epochs=5, learning_rate=0.0001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nORolmKhPERe"
      },
      "source": [
        "# step 4: Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeTuOaiMPERf"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# def evaluate_model(model, dataloader):\n",
        "#     # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     model.eval()\n",
        "\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#     total_loss = 0.0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for images, input_ids, attention_mask, labels in tqdm(dataloader, desc='Evaluation'):\n",
        "#             images, input_ids, attention_mask, labels = images.to(device), input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "#             outputs = model(images, input_ids, attention_mask)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             total_loss += loss.item() * images.size(0)\n",
        "#             _, predicted = torch.max(outputs.data, 1)\n",
        "#             total += labels.size(0)\n",
        "#             correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     average_loss = total_loss / len(dataloader.dataset)\n",
        "#     accuracy = correct / total\n",
        "\n",
        "#     print(f'Evaluation Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# # Example usage\n",
        "# evaluate_model(model, val_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE2cKjZ_PERf"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMYi8DAbPERf"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
