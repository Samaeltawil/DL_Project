{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LGKTsh9CPERX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, accuracy_score \n",
        "import shutil\n",
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au9o9WX5PERZ"
      },
      "source": [
        "# step 1: Preprocessing and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: 59245\n"
          ]
        }
      ],
      "source": [
        "batch_size = 5\n",
        "train_split = 0.8\n",
        "val_split = 0.1\n",
        "test_split = 0.1\n",
        "dataset_path = ''  # Set your dataset path here\n",
        "\n",
        "image_path = os.path.join(dataset_path, 'dataset/img_resized')\n",
        "img_text_path = os.path.join(dataset_path, 'dataset/img_txt')\n",
        "json_path = os.path.join(dataset_path, 'dataset/MMHS150K_GT.json')\n",
        "GT_path = os.path.join(dataset_path, 'dataset/MMHS150K_Custom.csv')\n",
        "split_save_path = os.path.join(dataset_path, 'dataset/splits')\n",
        "os.makedirs(split_save_path, exist_ok=True)\n",
        "\n",
        "# Custom Dataset Class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, image_dir):\n",
        "        self.data = data\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_filename, label = self.data[idx]\n",
        "        img_path = os.path.join(self.image_dir, str(img_filename) + \".jpg\")  # Add .jpg extension\n",
        "        return img_path, label\n",
        "\n",
        "# Load your dataset from CSV\n",
        "df = pd.read_csv(GT_path)\n",
        "image_filenames = df['user_id'].tolist()\n",
        "labels = df['hateful_label'].tolist()\n",
        "dataset = list(zip(image_filenames, labels))\n",
        "\n",
        "dataset_size = len(dataset)\n",
        "print(f\"Dataset size: {dataset_size}\")\n",
        "\n",
        "# Split dataset into training, validation, and test sets\n",
        "train_size = int(train_split * dataset_size)\n",
        "val_size = int(val_split * dataset_size)\n",
        "test_size = dataset_size - train_size - val_size\n",
        "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Save the dataset splits in a serializable format\n",
        "def save_split(dataset_split, filename):\n",
        "    serializable_split = [(img_filename, int(label)) for img_filename, label in dataset_split]\n",
        "    with open(os.path.join(split_save_path, filename), 'w') as f:\n",
        "        json.dump(serializable_split, f)\n",
        "\n",
        "save_split(train_set, 'train_set.json')\n",
        "save_split(val_set, 'val_set.json')\n",
        "save_split(test_set, 'test_set.json')\n",
        "\n",
        "# Load the dataset splits\n",
        "def load_split(filename):\n",
        "    with open(os.path.join(split_save_path, filename), 'r') as f:\n",
        "        loaded_split = json.load(f)\n",
        "    return [(img_filename, label) for img_filename, label in loaded_split]\n",
        "\n",
        "train_set = load_split('train_set.json')\n",
        "val_set = load_split('val_set.json')\n",
        "test_set = load_split('test_set.json')\n",
        "\n",
        "# Create data loaders for the splits\n",
        "def create_dataloader(dataset_split, image_dir, batch_size, shuffle=True, sampler=None):\n",
        "    dataset = CustomDataset(dataset_split, image_dir)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, sampler=sampler)\n",
        "\n",
        "train_loader = create_dataloader(train_set, image_path, batch_size)\n",
        "validation_loader = create_dataloader(val_set, image_path, batch_size)\n",
        "test_loader = create_dataloader(test_set, image_path, batch_size)\n",
        "\n",
        "# Calculate class weights for the training set\n",
        "total_counts = [label for _, label in train_set]\n",
        "total_not_hate = total_counts.count(0)\n",
        "total_hate = total_counts.count(1)\n",
        "total_samples = len(train_set)\n",
        "\n",
        "# Inverse of the frequency of each class\n",
        "class_weights = [total_samples / total_not_hate, total_samples / total_hate]\n",
        "\n",
        "# Apply class weights to training set\n",
        "weights_train = [class_weights[label] for _, label in train_set]\n",
        "sampler_train = WeightedRandomSampler(weights_train, len(weights_train))\n",
        "\n",
        "# Create data loader for balanced training set\n",
        "train_loader_balanced = DataLoader(CustomDataset(train_set, image_path), batch_size=batch_size, sampler=sampler_train)\n",
        "\n",
        "# Move images to respective directories\n",
        "def move_images(dataset_split, split_name):\n",
        "    split_dir = os.path.join(dataset_path, 'dataset', split_name)\n",
        "    os.makedirs(split_dir, exist_ok=True)\n",
        "    for img_filename, label in dataset_split:\n",
        "        img_path = os.path.join(image_path, str(img_filename) + \".jpg\")  # Add .jpg extension\n",
        "        shutil.copy(img_path, split_dir)\n",
        "\n",
        "# Move images after creating splits and samplers\n",
        "move_images(train_set, 'train')\n",
        "move_images(val_set, 'val')\n",
        "move_images(test_set, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_path = ''  # Update this path\n",
        "train_folder = os.path.join(dataset_path, 'val')\n",
        "csv_path = os.path.join(dataset_path, 'dataset/MMHS150K_Custom.csv')\n",
        "\n",
        "# Create directories for hate and not_hate\n",
        "hate_folder = os.path.join(train_folder, 'hate')\n",
        "not_hate_folder = os.path.join(train_folder, 'not_hate')\n",
        "os.makedirs(hate_folder, exist_ok=True)\n",
        "os.makedirs(not_hate_folder, exist_ok=True)\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Convert image IDs to the format they are saved with (i.e., add '.jpg')\n",
        "image_names_in_csv = {f\"{str(image_id)}.jpg\" for image_id in df['user_id'].values}\n",
        "\n",
        "# Iterate over all images in the train folder\n",
        "for image_name in os.listdir(train_folder):\n",
        "    # Skip the hate and not_hate folders if they exist in train_folder\n",
        "    if image_name in ['hate', 'not_hate']:\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(train_folder, image_name)\n",
        "\n",
        "    if image_name in image_names_in_csv:\n",
        "        # Get the label for the image from the CSV (by removing the '.jpg' part)\n",
        "        image_id = image_name[:-4]  # Removing '.jpg'\n",
        "        label = df[df['user_id'] == int(image_id)]['hateful_label'].values[0]\n",
        "        print(label)\n",
        "\n",
        "        # Move the image to the corresponding folder\n",
        "        if label == 1:\n",
        "            shutil.move(image_path, os.path.join(hate_folder, image_name))\n",
        "        else:\n",
        "            shutil.move(image_path, os.path.join(not_hate_folder, image_name))\n",
        "    else:\n",
        "        # Remove the image if it is not in the CSV\n",
        "        os.remove(image_path)\n",
        "        print(f\"Removed image {image_name} as it is not in the CSV file.\")\n",
        "\n",
        "print(\"Processing complete: Images have been moved to 'hate' and 'not_hate' folders or removed if not listed in the CSV.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Moo9Uy85PERc"
      },
      "source": [
        "# step 2: Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.2.18)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (10.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.11.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.3.0)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.2.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.12.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sama wael\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = Path(r'C:\\Users\\Sama Wael\\OneDrive\\Desktop\\Epfl\\MA2\\Deep Learning\\DL_Project\\data\\hateful_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.18  Python-3.11.5 torch-2.3.0+cpu CPU (Intel Core(TM) i9-10980HK 2.40GHz)\n",
            "Setup complete  (16 CPUs, 31.8 GB RAM, 934.8/952.5 GB disk)\n",
            "WARNING  no model scale passed. Assuming scale='n'.\n",
            "YOLOv8-cls summary: 99 layers, 2719288 parameters, 2719288 gradients, 4.4 GFLOPs\n",
            "Ultralytics YOLOv8.2.18  Python-3.11.5 torch-2.3.0+cpu CPU (Intel Core(TM) i9-10980HK 2.40GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8-cls.yaml, data=C:\\Users\\Sama Wael\\OneDrive\\Desktop\\Epfl\\MA2\\Deep Learning\\DL_Project\\data\\hateful_dataset, epochs=15, time=None, patience=100, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train11\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\Sama Wael\\OneDrive\\Desktop\\Epfl\\MA2\\Deep Learning\\DL_Project\\data\\hateful_dataset\\train... found 47396 images in 2 classes  \n",
            "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\Sama Wael\\OneDrive\\Desktop\\Epfl\\MA2\\Deep Learning\\DL_Project\\data\\hateful_dataset\\val... found 5924 images in 2 classes  \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "WARNING  no model scale passed. Assuming scale='n'.\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8-cls summary: 99 layers, 1440850 parameters, 1440850 gradients, 3.4 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Can not parse empty Comet API key\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING  Comet installed but not initialized correctly, not logging this run. Comet.ml requires an API key. Please provide as the first argument to Experiment(api_key) or as an environment variable named COMET_API_KEY \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Sama Wael\\OneDrive\\Desktop\\Epfl\\MA2\\Deep Learning\\DL_Project\\data\\hateful_dataset\\train... 47396 images, 0 corrupt: 100%|██████████| 47396/47396 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Sama Wael\\OneDrive\\Desktop\\Epfl\\MA2\\Deep Learning\\DL_Project\\data\\hateful_dataset\\val... 5924 images, 0 corrupt: 100%|██████████| 5924/5924 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "Image sizes 64 train, 64 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\classify\\train11\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "       1/15         0G     0.6158         16         64:  18%|█▊        | 528/2963 [01:36<08:04,  5.02it/s]"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "#Load Model\n",
        "model = YOLO('yolov8-cls.yaml')\n",
        "\n",
        "#Use Model\n",
        "results = model.train(data = DATA_DIR, epochs = 15, imgsz = 64)   ## Train the Model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
