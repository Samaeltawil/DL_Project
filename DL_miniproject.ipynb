{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW0c_XcTNE92",
        "outputId": "9781311a-bfd9-4cfc-d963-e67e3be233a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyunpack in /usr/local/lib/python3.10/dist-packages (0.3)\n",
            "Requirement already satisfied: easyprocess in /usr/local/lib/python3.10/dist-packages (from pyunpack) (1.1)\n",
            "Requirement already satisfied: entrypoint2 in /usr/local/lib/python3.10/dist-packages (from pyunpack) (1.1)\n",
            "Requirement already satisfied: patool in /usr/local/lib/python3.10/dist-packages (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyunpack\n",
        "!pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3QtameiMgUU"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image, read_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9ZQfvAtNxEl",
        "outputId": "f112d1cf-ed6d-4b9e-dbf6-02b4c01b24c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount google drive files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset_path = 'drive/MyDrive/DL_project/dataset_out'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bNIkmKTM0jt"
      },
      "outputs": [],
      "source": [
        "# from pyunpack import Archive\n",
        "# Archive('drive/MyDrive/DL_project/dataset.7z').extractall('drive/MyDrive/DL_project/')\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('drive/MyDrive/DL_project/dataset_out/dataset/img_txt.zip', 'r') as zipObj:\n",
        "  zipObj.extractall('drive/MyDrive/DL_project/dataset_out/dataset')\n",
        "# unzip_without_overwrite('drive/MyDrive/DL_project/dataset.7z','drive/MyDrive/DL_project/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check to see if we have good number of pictures\n",
        "dir_path = r'drive/MyDrive/DL_project/dataset_out/dataset/img_resized'\n",
        "# print(os.listdir(dir_path))\n",
        "count = 0\n",
        "for item in os.listdir(dir_path):\n",
        "    # check if current path is a file\n",
        "    count += 1\n",
        "print('File count:', count)"
      ],
      "metadata": {
        "id": "f8j0yrDyNVbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c389f651-3162-4c7a-9458-1757c9c8e544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File count: 70374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1DBzXEVQycB",
        "outputId": "5a446ec8-273f-4c6b-fbac-20faded1b6bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded anns: 149823\n",
            "Total Tweets Majority Voting: Not Hate: 112845, Hate: 36978, Racist: 11925, Sexist: 3495, Homophobe: 3870, Religion: 163, Other: 5811\n"
          ]
        }
      ],
      "source": [
        "anns = json.load(open(\"drive/MyDrive/DL_project/dataset_out/dataset/MMHS150K_GT.json\",\"r\"))\n",
        "print(\"Loaded anns: \" + str(len(anns)))\n",
        "\n",
        "majority_not_hate = 0\n",
        "majority_hate = 0\n",
        "majority_racist = 0\n",
        "majority_sexist = 0\n",
        "majority_homo = 0\n",
        "majority_religion = 0\n",
        "majority_other = 0\n",
        "\n",
        "for k,v in anns.items():\n",
        "    labels = []\n",
        "    label_num = []\n",
        "    # print(len(v[\"labels_str\"]))\n",
        "    for label in v[\"labels_str\"]:\n",
        "        if \"Not\" in label:\n",
        "            label_num.append(0)\n",
        "        elif \"Racist\" in label:\n",
        "            label_num.append(1)\n",
        "        elif \"Sexist\" in label:\n",
        "            label_num.append(2)\n",
        "        elif \"Homo\" in label:\n",
        "            label_num.append(3)\n",
        "        elif \"Religion\" in label:\n",
        "            label_num.append(4)\n",
        "        elif \"Other\" in label:\n",
        "            label_num.append(5)\n",
        "        else:\n",
        "            print(\"Error with: \" + label)\n",
        "            label = \"Error\"\n",
        "\n",
        "    if label_num.count(0) > 1:\n",
        "        majority_not_hate+=1\n",
        "    else:\n",
        "        majority_hate+=1\n",
        "        if label_num.count(1) > 1:\n",
        "            majority_racist+=1\n",
        "        elif label_num.count(2) > 1:\n",
        "            majority_sexist+=1\n",
        "        elif label_num.count(3) > 1:\n",
        "            majority_homo+=1\n",
        "        elif label_num.count(4) > 1:\n",
        "            majority_religion+=1\n",
        "        elif label_num.count(5) > 1:\n",
        "            majority_other+=1\n",
        "\n",
        "print(\"Total Tweets Majority Voting: Not Hate: \" + str(majority_not_hate) + \", Hate: \" + str(majority_hate) + \", Racist: \" + str(majority_racist) + \", Sexist: \" + str(majority_sexist) + \", Homophobe: \" + str(majority_homo) + \", Religion: \" + str(majority_religion) + \", Other: \" + str(majority_other))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Gd5Wdfr-Mh9_"
      },
      "outputs": [],
      "source": [
        "image_path = os.path.join(dataset_path, 'dataset/img_resized')\n",
        "text_path = os.path.join(dataset_path, 'dataset/img_txt')\n",
        "GT_path = os.path.join(dataset_path, 'dataset/MMHS150K_GT.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTdiyuhnMi18"
      },
      "outputs": [],
      "source": [
        "def majority_element(arr):\n",
        "    count_zeros = arr.count(0)\n",
        "    count_ones = arr.count(1)\n",
        "\n",
        "    if count_zeros > count_ones:\n",
        "        return 0\n",
        "    elif count_ones > count_zeros:\n",
        "        return 1\n",
        "    else:\n",
        "        return None  # No majority element\n",
        "\n",
        "def hateful_or_not(labels):\n",
        "    labels_list = labels.copy()\n",
        "    for label_id in range(len(labels_list)):\n",
        "        if labels_list[label_id] != 0:\n",
        "            labels_list[label_id] = 1\n",
        "\n",
        "    return majority_element(labels_list)\n",
        "\n",
        "def create_csv_labels(json_file, csv_file):\n",
        "    with open(json_file, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    with open(csv_file, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['user_id', 'labels', 'hateful_label', 'text']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Iterate over each user ID in the JSON file\n",
        "        for user_id, user_data in data.items():\n",
        "            labels = user_data.get('labels', [])\n",
        "            text = user_data.get('tweet_text', [])\n",
        "            hateful_label = hateful_or_not(labels)\n",
        "            # Write data to CSV file\n",
        "            writer.writerow({'user_id': user_id, 'labels': labels, 'hateful_label': hateful_label, 'text': text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIg3dJkzMmzC"
      },
      "outputs": [],
      "source": [
        "# uncomment the first time\n",
        "create_csv_labels(dataset_path + '/dataset/MMHS150K_GT.json', GT_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "TV_kvlJJMpdS"
      },
      "outputs": [],
      "source": [
        "class MMHS_150KDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, GT_path, image_path, transform=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.GT_path = GT_path\n",
        "        self.GT_data = pd.read_csv(GT_path)\n",
        "        self.idx_list = []\n",
        "        # self.root_dir = root_dir\n",
        "        self.image_path = image_path\n",
        "        # self.text_path = text_path\n",
        "        self.transform = transform\n",
        "\n",
        "        self.refine_images()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        ID = self.GT_data.iloc[idx, 0]\n",
        "        # txt_path = os.path.join(self.text_path, str(ID) + '.json').replace(\"\\\\\",\"/\")\n",
        "        img_path = os.path.join(self.image_path, str(ID) + '.jpg').replace(\"\\\\\",\"/\")\n",
        "        print(img_path)\n",
        "        # print(txt_path)\n",
        "\n",
        "        try:\n",
        "          image = read_image(img_path)\n",
        "        except:\n",
        "          pass\n",
        "        # f = open(text_path, 'r')\n",
        "        # data = json.load(f)\n",
        "        # text = data['img_text']\n",
        "        # text = f.read()\n",
        "\n",
        "        # text = read_file(txt_path)\n",
        "\n",
        "        text = self.GT_data.iloc[idx, 3]\n",
        "\n",
        "        label = self.GT_data.iloc[idx, 2]\n",
        "\n",
        "        # sample = {'ID': ID, 'text': text, 'label': label}\n",
        "        sample = {'ID': ID, 'text': text, 'image': image, 'label': label}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def refine_images(self):\n",
        "      GT_path_cleared = os.path.join(dataset_path, 'dataset/MMHS150K_GT_cleared.csv')\n",
        "      cmpt = 0\n",
        "      with open(GT_path, 'r') as readFile:\n",
        "        lines = readFile.readlines()\n",
        "        for row in lines[1:]:\n",
        "          idx = row[0:19]\n",
        "          img_path = os.path.join(self.image_path, str(idx) + '.jpg').replace(\"\\\\\",\"/\")\n",
        "          # look if the image exists, otherwise delete the idx from the csv\n",
        "          if not (os.path.isfile(img_path)):\n",
        "            lines.remove(row)\n",
        "            cmpt = cmpt + 1\n",
        "\n",
        "      with open(GT_path_cleared, 'w') as writeFile:\n",
        "        for line in lines:\n",
        "          writeFile.write(line)\n",
        "\n",
        "      self.len_samples = len(lines)\n",
        "      self.GT_data =  pd.read_csv(GT_path_cleared)\n",
        "      # print(f\"nbr_missing = {cmpt}\")\n",
        "      # print(f\"len = {len(self.GT_data.iloc[:, 0])}\")\n",
        "      # print(f\"linelen = {len(lines)}\")\n",
        "\n",
        "# example = MMHS_150KDataset(GT_path, image_path)\n",
        "# example[10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "vuG8UDLhb3Ro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099fa90f-295e-4952-ea38-7e2ffcbfa087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70328\n",
            "7032 3516\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "dataset = MMHS_150KDataset(GT_path, image_path)\n",
        "batch_size = 16\n",
        "validation_split = .1\n",
        "test_split = .5 # corresponds to half ot the validation set\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "print(dataset_size)\n",
        "indices = list(range(dataset_size))\n",
        "validation_split = int(np.floor(validation_split * dataset_size))\n",
        "test_split = int(np.floor(test_split * validation_split))\n",
        "print(validation_split, test_split)\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices, test_indices = indices[validation_split:], indices[test_split:validation_split], indices[:test_split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                           sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                                sampler=test_sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbckVLd7aTux"
      },
      "outputs": [],
      "source": [
        "# class MMHS150KDataset(Dataset):\n",
        "#     \"\"\"MMHS150K dataset.\"\"\"\n",
        "\n",
        "#     def __init__(self, label_id_path, txt_path, images_path, transform=None):\n",
        "#         \"\"\"\n",
        "#         Arguments:\n",
        "#             label_id_path (string): Path to the MMHS150K_GT.json which contains\n",
        "#                                     the IDs and labels corresponding\n",
        "#             txt_path (string): Path to the text file with annotations.\n",
        "#             images_path (string): Directory with all the images.\n",
        "#             transform (callable, optional): Optional transform to be applied\n",
        "#                 on a sample.\n",
        "#         \"\"\"\n",
        "#         self.label_id_path = label_id_path\n",
        "#         self.txt_path = txt_path\n",
        "#         self.images_path = images_path\n",
        "#         self.transform = transform"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}